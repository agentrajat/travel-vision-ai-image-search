{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\mos\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from web_crawler import CustomWebCrawler\n",
    "from computer_vision import VisionTransformer, BLIPImageCaptioning, download_image\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./models/vit-base-patch16-224\"\n",
    "CAPTION_MODEL_PATH = \"./models/blip-image-captioning-large\"\n",
    "\n",
    "PROJECT_TOPIC = \"travel\"\n",
    "IMAGE_LIMIT = 10000\n",
    "IMAGES_PER_GROUP = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./outputs/crawler.json\"):\n",
    "    os.makedirs(\"./outputs\", exist_ok=True)\n",
    "\n",
    "    spider = CustomWebCrawler(photo_limit=IMAGE_LIMIT, photos_per_group=IMAGES_PER_GROUP)\n",
    "\n",
    "    data = [x for x in spider.crawl(PROJECT_TOPIC)]\n",
    "\n",
    "    spider.close()\n",
    "\n",
    "    with open(\"./outputs/crawler.json\", \"w\") as f:\n",
    "        f.write(str(data))\n",
    "else:\n",
    "    with open(\"./outputs/crawler.json\", \"r\") as f:\n",
    "        data = eval(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(id, image):\n",
    "    if not os.path.exists(\"./images\"):\n",
    "        os.mkdir(\"./images\")\n",
    "    \n",
    "    image.save(f\"./images/{id}.jpg\")\n",
    "\n",
    "def load_image(id, src):\n",
    "    if os.path.exists(f\"./images/{id}.jpg\"):\n",
    "        return Image.open(f\"./images/{id}.jpg\")\n",
    "    else:\n",
    "        try:\n",
    "            return download_image(src)\n",
    "        except:\n",
    "            print(f\"Failed to download image {id} from {src}\")\n",
    "            return None\n",
    "\n",
    "if not os.path.exists(\"./outputs/search-data.json\"):\n",
    "    os.makedirs(\"./outputs\", exist_ok=True)\n",
    "\n",
    "    vit = VisionTransformer(model_path=MODEL_PATH)\n",
    "    blip = BLIPImageCaptioning(model_path=CAPTION_MODEL_PATH)\n",
    "\n",
    "    for i, item in enumerate(data):\n",
    "        print(f\"\\rProcessing Image {i+1}/{len(data)}...\", end=\"\")\n",
    "\n",
    "        if item.get('caption') is not None:\n",
    "            continue\n",
    "\n",
    "        image = load_image(i, item[\"image_src\"])\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        classification = vit.classify(image)\n",
    "        caption = blip.caption(image)\n",
    "\n",
    "        item[\"cv\"] = classification\n",
    "        item[\"caption\"] = caption\n",
    "        item[\"docno\"] = i\n",
    "        save_image(i, image)    \n",
    "\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "    with open(\"./outputs/search-data.json\", \"w\") as f:\n",
    "        f.write(str(data))\n",
    "else:\n",
    "    with open(\"./outputs/search-data.json\", \"r\") as f:\n",
    "        data = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out images which failed to download\n",
    "data = [x for x in data if x.get('caption') is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading data to Firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import firestore\n",
    "\n",
    "db = firestore.Client(project=\"ca6005-search-engine\", database=\"search-engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"image-data\"\n",
    "\n",
    "batch = db.batch()\n",
    "batch_size = 500\n",
    "\n",
    "def add_to_batch(doc, batch):\n",
    "    doc_ref = db.collection(COLLECTION_NAME).document(str(doc.get(\"docno\")))\n",
    "    batch.set(doc_ref, doc)\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    print(f\"\\rUploading Image {i+1}/{len(data)}...\", end=\"\")\n",
    "\n",
    "    add_to_batch(item, batch)\n",
    "\n",
    "    if i % batch_size == 0:\n",
    "        batch.commit()\n",
    "        batch = db.batch()\n",
    "\n",
    "batch.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading images to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.storage import transfer_manager\n",
    "from google.cloud import storage\n",
    "\n",
    "storage_client = storage.Client(project=\"ca6005-search-engine\")\n",
    "bucket = storage_client.bucket(\"ca6005-search-engine\")\n",
    "\n",
    "# Upload images to bucket\n",
    "source_directory = \"./images\"\n",
    "workers = 10\n",
    "\n",
    "filenames = [f\"{source_directory}/{item.get('docno')}.jpg\" for item in data]\n",
    "\n",
    "if len(filenames) > 0:\n",
    "    results = transfer_manager.upload_many_from_filenames(\n",
    "        bucket, filenames, max_workers=workers\n",
    "    )\n",
    "\n",
    "    for name, result in zip(filenames, results):\n",
    "\n",
    "        if isinstance(result, Exception):\n",
    "            print(\"Failed to upload {} due to exception: {}\".format(name, result))\n",
    "        else:\n",
    "            print(\"Uploaded {} to {}.\".format(name, bucket.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for blob in bucket.list_blobs():\n",
    "    ls.append(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/9999.jpg'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rajat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rajat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing... (9999 / 9999)\n",
      "Indexing completed.\n"
     ]
    }
   ],
   "source": [
    "from indexing import Indexing\n",
    "\n",
    "index_file = \"./index-data.pkl\"\n",
    "\n",
    "index = Indexing()\n",
    "index.build_index(data)\n",
    "index.save_object(index_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
